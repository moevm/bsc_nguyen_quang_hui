# Анализ генетического алгоритма для построения нелинейной регрессии

Ключевые слова: генетический алгоритм, построение нелинейной регрессия, вид функциональной зависимости.

## Аннотация

Целью данной статьи является выявление преимуществ генетического алгоритма при построении нелинейной регрессии. Для достижения поставленной цели выполнен сравнительный анализ генетического алгоритма с существующими аналогами, применяемыми для построения нелинейной регрессии. На основании сравнения обозначены преимущества генетического алгоритма, описаны его особенности в задаче построения нелинейной регрессии.


## Введение

Методы регрессионного анализа широко используются при анализе экспериментальных данных в различных областях науки: психологии, экономике, социологии, физике, химии, геологии, автоматике и др. Подбор функции регрессии чаще всего производится с применением теории той конкретной науки, на базе которой возникает задача измерения связи между явлениями. О характере зависимости между экономическими явлениями часто судят по внешнему виду эмпирического графика регрессии. Однако при малом числе наблюдений этот путь приводит к неудовлетворительным результатам или, наоборот, при большом количестве наблюдений можно наблюдать разброс данных, в следствие чего не удается выявить вид функциональной зависимости. Проблемой в данном случае является то, что стандартные методы построения нелинейной регрессии подразумевают заранее известный вид функциональной зависимости.  Попыткой решить проблемы, связанные с построением нелинейных регрессий, является применение генетического алгоритма. Целью данного исследования является выявление преимуществ генетического алгоритма при построении нелинейной регрессии по сравнению с традиционными методами регрессионного анализа. Объектом исследования данной работы являются способы построения нелинейной регрессии. Предметом исследования – преимущества генетического алгоритма для построения нелинейной регрессии. Для достижения поставленной цели необходимо провести обзор существующих методов построения нелинейной регрессии, рассмотреть возможность выбранных методов определять вид функциональной зависимости, провести анализ генетического алгоритма в задаче построения нелинейной регрессии, а также сформировать общий вывод по проделанному обзору и анализу методов построения нелинейной регрессии.

## Обзор предметной области

Чтобы выявить преимуществ применения генетического алгоритма для построения нелинейной регрессии, необходимо провести сравнительный анализ с существующими аналогами для построения нелинейной регрессии. Нелинейные регрессии делятся на два класса.  К первому классу относятся регрессии, нелинейные относительно включенных в анализ объясняющих переменных ![equtation](https://latex.codecogs.com/gif.latex?x_{k}), но линейные по неизвестным, подлежащим оценке параметрам регрессии ![equtation](https://latex.codecogs.com/gif.latex?b_{k}), k=1,2,…,p. Второй класс регрессии характеризуется нелинейностью по оцениваемым параметрам [1]. 
Основными критериями в выборе аналогов являлись: 
1. возможность применения алгоритма для построения нелинейной регрессии хотя бы для одного класса; 
2. выбранный алгоритм должен быть описан суммарно не менее, чем в шестидесяти статьях журналов ВАК и Scopus.


**Метод наименьших квадратов (МНК)** — математический метод, применяемый для решения различных задач, основанный на минимизации суммы квадратов отклонений некоторых функций от искомых переменных. Он может использоваться для «решения» переопределенных систем уравнений (когда количество уравнений превышает количество неизвестных), для поиска решения в случае обычных (не переопределенных) нелинейных систем уравнений, для аппроксимации точечных значений некоторой функции. МНК является одним из базовых методов регрессионного анализа для оценки неизвестных параметров регрессионных моделей по выборочным данным [1]. Функция, нелинейная по объясняющим переменным, но линейная по оцениваемым параметрам, имеет вид:
![equtation](https://latex.codecogs.com/gif.latex?\widehat{y}&space;=&space;b_{0}&plus;&space;b_{1}&space;F_{1}(x)&plus;&space;b_{2}&space;F_{2}(x)&space;&plus;...&plus;&space;b_{p}&space;F_{p}(x)),
где ![equtation](https://latex.codecogs.com/gif.latex?F_{1}(x),&space;F_{2}(x),&space;...) - функции от объясняющих переменных x. 
Применяя метод наименьших квадратов к данному, выводятся системы нормальных уравнений: 
![equtation](https://latex.codecogs.com/gif.latex?\sum_i&space;y_{i}=&space;n&space;b_{0}&plus;&space;b_{1}&space;\sum&space;F_{1}(x)&space;&plus;b_{2}&space;\sum&space;F_{2}(x)&space;&plus;&space;...)
![equtation](https://latex.codecogs.com/gif.latex?\sum_i&space;y_{i}&space;F_{1}(x)=&space;b_{0}&space;\sum&space;F_{1}(x)&plus;&space;b_{1}\sum&space;F^{2}&space;_{1}(x)&plus;&space;b_{2}&space;\sum&space;F_{1}(x)&space;F_{2}(x)&plus;&space;...)
![equtation](https://latex.codecogs.com/gif.latex?\sum_i&space;y_{i}&space;F_{2}(x)=&space;b_{0}&space;\sum&space;F_{2}(x)&plus;&space;b_{1}\sum&space;F_{1}(x)F_{2}(x)&plus;&space;b_{2}&space;\sum&space;F^{2}&space;_{2}(x)&plus;&space;...)
Решив систему нормальных уравнений, можно получить параметры регрессии. 
Достоинство метода наименьших квадратов заключается в сведении всех вычислительных процедур к простому вычислению неизвестных коэффициентов. Недостатком данного метода является его применимость только к линейным по неизвестным, подлежащим оценке параметрам регрессии.

**Линеаризация** — один из методов приближённого представления замкнутых нелинейных систем, при котором исследование нелинейной системы заменяется анализом линейной системы, в некотором смысле эквивалентной исходной [2]. Путем логарифмического преобразования можно перейти от зависимости показательного типа к линейной:
![equtation](https://latex.codecogs.com/gif.latex?\widehat{y}=a&space;b^{x}), 
![equtation](https://latex.codecogs.com/gif.latex?log&space;\widehat{y}=&space;log&space;a&plus;x&space;log&space;b). 
Достоинством данного метода является применимость его ко второму классу нелинейной регрессии. Однако это осуществимо только по отношению к степенной функции.  

**Алгоритм Левенберга-Марквардта** предназначен для оптимизации параметров нелинейных регрессионных моделей. Предполагается, что в качестве критерия оптимизации используется среднеквадратичная ошибка модели на обучающей выборке. Алгоритм заключается в последовательном приближении заданных начальных значений параметров к искомому локальному оптимуму [3]. Его преимуществами являются большая скорость счета и обеспечение сходимости [6]. Недостатком является применимость только к первому классу нелинейной регрессии.

**Искусственная нейронная сеть** — математическая модель, а также её программное или аппаратное воплощение, построенная по принципу организации и функционирования биологических нейронных сетей — сетей нервных клеток живого организма. Возможность обучения — одно из главных преимуществ нейронных сетей перед традиционными алгоритмами. Технически обучение заключается в нахождении коэффициентов связей между нейронами [5].

**Генетический алгоритм** – это эвристический алгоритм поиска, используемый для решения задач оптимизации и моделирования путём случайного подбора, комбинирования и вариации искомых параметров с использованием механизмов, аналогичных естественному отбору в природе. Алгоритм является разновидностью эволюционных вычислений, с помощью которых решаются оптимизационные задачи с использованием методов естественной эволюции, таких как наследование, мутации, отбор и кроссинговер [5]. Преимуществом генетического алгоритма является его применимость к обоим классам нелинейной регрессии. Кроме того, в процессе работы алгоритм не использует никакой дополнительной информации кроме данных об области допустимых значений параметров и целевой функции в произвольной точке. Результаты применения генетического алгоритма ограничиваются тем, какие настройки используются для генетических операторов скрещивания, мутации и репродукции. 
Сравнение аналогов проводилось по трём критериям: «применимость алгоритма к различным классам нелинейной регрессии», «способность алгоритма выявлять вид зависимости», «необходимость существования первой производной для приближаемой функции».  Подробное описание каждого из критериев представлено далее. 


1.	**Применимость алгоритма к различным классам нелинейной регрессии.** Данный критерий необходим для решения поставленной задачи. Критерий показывает применимость алгоритма к различным классам нелинейной регрессии, тем самым раскрывает полноту возможности решения задач с его помощью. 
2.	**Способность алгоритма выявлять вид зависимости.** Традиционный подход построения нелинейной регрессии предполагает, что наблюдаемую нелинейную зависимость можно аппроксимировать некоторой функцией из заранее определенного ограниченного набора нелинейных функций, также заданных с точностью до неизвестных параметров, которые подгоняются к наблюдаемым данным. Однако не всегда очевидно, какую именно функцию следует выбрать, чтобы наилучшим образом аппроксимировать наблюдаемые данные. Данный критерий отображает основную проблему исследования: способность алгоритма выявлять вид зависимости.   

3.	**Необходимость существования первой производной для приближаемой функции.** Некоторые алгоритмы построены на вычислении первой производной для приближаемой функцией. Недостаток данного подхода заключается в том, что это не всегда возможно. Пример непрерывной функции, нигде не имеющей производной: функция Вейерштрасса [4].

Результаты сравнения по данным критериям представлены ниже в таблице 1.

Таблица 1 – Сравнение аналогов
|   | Применимость алгоритма к различным классам нелинейной регрессии | Способность алгоритма выявлять вид зависимости | Необходимость существования первой производной для приближаемой функции  |
| --- | --- | --- | --- |
| Метод наименьших квадратов       | I класс | Нет | Да |
| Линеаризация методом логарифмирования  | Применим ко II классу только в случае степенной функции | Нет | Да |
| Алгоритм Левенберга-Марквардта | I класс | Нет | Да |
| Нейронные сети | I и II класс | Да | Нет |
| Генетический алгоритм | I и II класс | Да | Нет |


По итогам сравнения можно сделать вывод, что применимость первого и третьего аналогов только к регрессиям, относящимся к первому классу - является их существенным недостатком, потому что данные методы не работают в случае нелинейных по оцениваемым параметрам регрессий, а следовательно, не способны в полной мере решить поставленную задачу. Также первые три метода не способны выявлять вид функциональной зависимости, следовательно не решают основную проблему данного исследования. Недостатком первых трёх аналогов является необходимость подсчета производных. При сложных функциях данная процедура оказывается утомительной с программистской точки зрения, а также приводит к громоздким вычислениям на каждой итерации. Достоинствами нейронной сети и генетического алгоритма является их применимость к обоим классам нелинейной регрессии, а также способность выявлять вид функциональной зависимости, что делает их более гибкими в решении различного спектра задач. 

## Выбор метода решения

Обзор существующих алгоритмов помог выявить значительные их недостатки, такие как: 
1.	большинство аналогов применимы только к первому классу регрессии;
2.	большинство аналогов не способны выявлять вид функциональной зависимости.
 Главное преимущество генетического алгоритма над данными алгоритмами состоит в том, что он применим как к регрессиям, нелинейным относительно включенных в анализ объясняющих переменных, но линейных по неизвестным, подлежащим к оценке параметрам, так и нелинейным по оцениваемым параметрам, а также способность выявлять вид функциональной зависимости. Это обусловлено следующими особенностями генетического алгоритма: 
1.	способность со сколь угодно заданной точностью воспроизводить (аппроксимировать) произвольные нелинейные зависимости, вид которых заранее неизвестен;
2.	способность улавливать скрытые нелинейные зависимости;
3.	способность адаптироваться к изменившимся условиям;
4.	использование только целевой функции, а не ее производных либо иную дополнительную информацию.
 Данные могут характеризоваться сложными, скрытыми, нелинейными связями, которые невозможно аппроксимировать с помощью элементарных функций. Структура этих связей с течением времени может меняться, а, следовательно, должна меняться и структура модели. Исходя из этого, можно сделать вывод, что генетический алгоритм лучше всего подходит для решения проблемы. Далее рассмотрим, как работает классический генетический алгоритм.

## Описание метода решения

Классический генетический алгоритм состоит из следующих шагов [7]: 

1) инициализация, или выбор исходной популяции хромосом; 
2) оценка приспособленности хромосом в популяции;
3) проверка условия остановки алгоритма; 
4) селекция хромосом;
5) применение генетических операторов; 
6) формирование новой популяции; 
7) выбор «наилучшей» хромосомы.

**Инициализация**, т. е. формирование исходной популяции, заключается в случайном выборе заданного количества хромосом (особей), представляемых двоичными последовательностями фиксированной длины.
**Оценивание приспособленности хромосом в популяции** состоит в расчете функции приспособленности для каждой хромосомы этой популяции. Чем больше значение этой функции, тем выше «качество» хромосомы. Форма функции приспособленности зависит от характера решаемой задачи. Предполагается, что функция приспособленности всегда принимает неотрицательные значения и, кроме того, что для решения оптимизационной задачи требуется максимизировать эту функцию. 
**Проверка условия остановки алгоритма.** Определение условия остановки генетического алгоритма зависит от его конкретного применения. В оптимизационных задачах, если известно максимальное (или минимальное) значение функции приспособленности, то остановка алгоритма может произойти после достижения ожидаемого оптимального значения, возможно – с заданной точностью. Остановка алгоритма также может произойти в случае, когда его выполнение не приводит к улучшению уже достигнутого значения. Алгоритм может быть остановлен по истечении определенного времени выполнения либо после выполнения заданного количества итераций. Если условие остановки выполнено, то производится переход к завершающему этапу выбора «наилучшей» хромосомы. В противном случае на следующем шаге выполняется селекция. 
**Селекция хромосом заключается в выборе** тех хромосом, которые будут участвовать в создании потомков для следующей популяции, т. е. для очередного поколения. Такой выбор производится согласно принципу естественного отбора, по которому наибольшие шансы на участие в создании новых особей имеют хромосомы с наибольшими значениями функции приспособленности. В результате процесса селекции создается родительская популяция, также называемая родительским пулом с численностью N, равной численности текущей популяции.
**Применение генетических операторов к хромосомам**, отобранным с помощью селекции, приводит к формированию новой популяции потомков от созданной на предыдущем шаге родительской популяции. 
**Оператор скрещивания.** На первом этапе скрещивания выбираются пары хромосом из родительской популяции (родительского пула). Это временная популяция, состоящая из хромосом, отобранных в результате селекции и предназначенных для дальнейших преобразований операторами скрещивания и мутации с целью формирования новой популяции потомков. На данном этапе хромосомы из родительской популяции объединяются в пары.
**Оператор мутации.** Оператор мутации с вероятностью изменяет значение гена в хромосоме на противоположное (т. е. с 0 на 1 или обратно). 
**Формирование новой популяции.** Хромосомы, полученные в результате применения генетических операторов к хромосомам временной родительской популяции, включаются в состав новой популяции. На каждой очередной итерации рассчитываются значения функции приспособленности для всех хромосом этой популяции, после чего проверяется условие остановки алгоритма и либо фиксируется результат в виде хромосомы с наибольшим значением функции приспособленности, либо осуществляется переход к следующему шагу генетического алгоритма, т. е. к селекции. В классическом генетическом алгоритме вся предшествующая популяция хромосом замещается новой популяцией потомков, имеющей ту же численность. Выбор «наилучшей» хромосомы. Если условие остановки алгоритма выполнено, то выводится результат работы, т. е. представляется искомое решение задачи. Лучшим решением считается хромосома с наибольшим значением функции приспособленности.


## Заключение

В рамках данного исследования была достигнута поставленная цель – выявлены преимущества генетического алгоритма для построения нелинейной регрессии. Для этого был проведен сравнительный анализ существующих аналогов по следующим критериям: «применимость алгоритма к различным классам нелинейной регрессии», «способность алгоритма выявлять вид зависимости», «необходимость существования первой производной для приближаемой функции».  По результатам сравнения были выявлены основные преимущества генетического алгоритма: применимость как к регрессиям, нелинейным относительно включенных в анализ объясняющих переменных, но линейных по неизвестным, подлежащим к оценке параметрам, так и нелинейным по оцениваемым параметрам, а также способность выявлять вид функциональной зависимости. Данные особенности генетического алгоритма решают проблему исследования.  
Направления дальнейших исследований включают в себя практическое увеличение точности и скорости построения нелинейных регрессий с помощью применения генетического алгоритма. 

## Список литературы

1. Фёрстер Э., Рёнц Б. Методы корреляционного и регрессионного анализа. Руководство для экономистов. Перевод с немецкого и предисловие В. М. Ивановой, М.: "Финансы и статистика", 1983 г.- 304 с. 
2. Айвазян С. А. и др. Прикладная статистика: Основы моделирования и первичная обработка данных. Справочное изд. / С. А. Айвазян, И. С. Енюков, Л. Д. Мешалкин. — М.: Финансы и статистика, 1983. — 471 с.
3. Levenberg, K. A Method for the Solution of Certain Problems in Last Squares. Quart. Appl. Math. 1944. Vol. 2. P. 164—168.
4. Hardy G. H. Weierstrass’s nondifferentiable function // Trans — Amer. Math. Soc, 17 (1916), р. 301—325.
5. Рутковская Д., Пилиньский М., Рутковский Л. Нейронные сети, генетические алгоритмы и нечеткие системы: Пер. с польск. И. Д. Рудинского. - М.: Горячая линия -Телеком, 2006. - 452 c.
6. Marquardt D. An Algorithm for Least-Squares Estimation of Nonlinear Parameters // SIAM Journal on Applied Mathematics. – 1963. – Vol. 11, N 2. – P. 431–441.
7. А.А. Андреев, ПРИМЕНЕНИЕ ГЕНЕТИЧЕСКИХ АЛГОРИТМОВ ПРИ ОПТИМИЗАЦИИ НЕЛИНЕЙНЫХ ФУНКЦИЙ URL: https://cyberleninka.ru/article/n/primenenie-geneticheskih-algoritmov-pri-optimizatsii-nelineynyh-funktsiy/viewer
